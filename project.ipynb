{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caae3a83",
   "metadata": {},
   "source": [
    "Using machine learning based methods to identify defaults in matter during laser powder processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572ec8c7",
   "metadata": {},
   "source": [
    "#### Prior python installs (Tip : Don't forget to generate a virtual environment so as not to clutter your python workspaces)\n",
    "\n",
    "!pip install soundfile \\\n",
    "!pip install sounddevice\\\n",
    "!pip install scipy \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d00d6806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.fftpack\n",
    "\n",
    "\n",
    "import wave\n",
    "import struct\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import resample\n",
    "\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "\n",
    "import os\n",
    "\n",
    "from IPython import display\n",
    "from IPython.display import Audio\n",
    "\n",
    "#import tensorflow for yamnet\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "\n",
    "data_folder = './data/'\n",
    "wav_folder_rx ='./samples_A_RX1_C0/'\n",
    "wav_folder_deformed ='./samples_A_DEFORMED1_C0/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c05e5afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CSV filenames\n",
    "deformed01 = 'A_DEFORMED1_C0'\n",
    "deformed02 = 'A_DEFORMED1_C0'\n",
    "rx01 = 'A_RX1_C0'\n",
    "\n",
    "#WAV filenames\n",
    "wav_rx = 'sample_A_RX1_C00'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93ee88b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_folder + deformed02 + '.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eefc87f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0872443d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the frequency of the signal is 3.04878048780488 MHz\n",
      "the total duration of the signal is 10.495999999999993 seconds\n",
      "number of samples : 32000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#initialisation of clock variables\n",
    "clock = 3048780.48780488\n",
    "delay_in_samples = 304878\n",
    "g_T = 1 / clock\n",
    "g_N = len(df)\n",
    "\n",
    "print(\"the frequency of the signal is\", clock * 1e-6, \"MHz\")\n",
    "print(\"the total duration of the signal is\", g_N / clock, \"seconds\")\n",
    "print(\"number of samples :\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5f3252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8b69d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a second array containing the timestamps of my dataset: \n",
    "def prepareData(df,T):\n",
    "    df['time'] = np.arange(len(df)) * T\n",
    "    df.rename(columns = {0:'amplitude'}, inplace = True)\n",
    "    return df \n",
    "\n",
    "conduction = prepareData(df.copy(), g_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be551ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "conduction.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b074c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#small snapshot to visualize the signal\n",
    "\n",
    "\n",
    "#THERE IS A MAJOR ISSUE BECAUSE I DID NOT DEFINE TIME AS AN ORDERED INDEX. SO WHEN I EXTRACT THE SIGNAL IM ITERATING OVER \n",
    "#A SHIT TON OF VALUES (THE FULL SIZE OF THE SIGNAL) INSTEAD OF SIMPLY GOING ON THE RANGE OF THE INDEX\n",
    "def extract_signal(signal, startTime, endTime):\n",
    "    smaller_signal = conduction[conduction['time'].apply(lambda x: (x > startTime) & (x < endTime))]\n",
    "    small_T = g_T\n",
    "    small_N = len(smaller_signal)\n",
    "    return smaller_signal, small_N, small_T\n",
    "    \n",
    "\n",
    "def showFFT(signal, N, T):\n",
    "    amplitudes = signal['amplitude'].to_numpy()\n",
    "    x = np.linspace(0.0, N*T, N, endpoint=False)\n",
    "    y = amplitudes\n",
    "    yf = scipy.fftpack.fft(amplitudes)\n",
    "    xf = scipy.fftpack.fftfreq(N, T)[:N//2]\n",
    "    plt.plot(xf, 2.0/N * np.abs(yf[0:N//2]))\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    print(\"Fourier transform of the signal\")\n",
    "    \n",
    "def plot_signal(signal):\n",
    "    signal.plot(x='time', y='amplitude')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a3c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_signal, sample_N, sample_T = extract_signal(conduction,2e-4,3e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547c9389",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_signal(sample_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bac2eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "showFFT(sample_signal, sample_N, sample_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45e9099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d4757ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted 1.3556525359999991 samples from the end because we assume it is silence from 10.495999999999993 samples\n"
     ]
    }
   ],
   "source": [
    "#remove the last points so that the array length is divisible by the number of points per sample \n",
    "#in order to have equal lengths sample\n",
    "def clean_data(df):\n",
    "    epsilon =  1e-1\n",
    "    #remove the silence at the end: \n",
    "    for i in range(len(df) - 1, 0, -1):\n",
    "        if(df[0][i] > epsilon):\n",
    "            print(\"deleted\", (len(df) - i) / clock, \"samples from the end because we assume it is silence from\", len(df) / clock, \"samples\")\n",
    "            return df[:i]\n",
    "\n",
    "def split_csv(filename, T):\n",
    "    df = pd.read_csv(data_folder + filename + '.csv', header = None)\n",
    "    df = clean_data(df)\n",
    "    df.rename(columns = {0:'amplitude'}, inplace = True)\n",
    "    point_per_sample = int(160e-3 * clock)\n",
    "    \n",
    "    nb_of_samples = int(len(df)/point_per_sample)\n",
    "    data = df[:nb_of_samples * point_per_sample]\n",
    "    return np.array_split(data, nb_of_samples)\n",
    "\n",
    "data_deformed = split_csv(deformed01, g_T)\n",
    "#data_rx = split_csv(rx01, g_T)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b3d32ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "#Wavelets\n",
    "t = np.linspace(-1, 1, 200, endpoint=False)\n",
    "sig  = np.cos(2 * np.pi * 7 * t) + signal.gausspulse(t - 0.4, fc=2)\n",
    "flat_list = []\n",
    "widths = np.arange(1, 31)\n",
    "for sublist in data_deformed:\n",
    "    \n",
    "     for item in sublist['amplitude']:\n",
    "        flat_list.append(item)\n",
    "\n",
    "\n",
    "\n",
    "#cwt = signal.cwt(data_deformed, signal.ricker,widths)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a3c898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a80f2054",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'signal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yd/mh_zcn295tl15dz8w8jr2p7h0000gn/T/ipykernel_67676/3535313042.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcwt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcwt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mricker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwidths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'signal' is not defined"
     ]
    }
   ],
   "source": [
    "cwt = signal.cwt(flat_list[:200], signal.ricker,widths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37728301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14f3d8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cwt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yd/mh_zcn295tl15dz8w8jr2p7h0000gn/T/ipykernel_67676/2826948712.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"h\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcwt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cwt' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(\"h\")\n",
    "plt.plot(cwt[:200])\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e0e4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Transforming the data into a .wav file\n",
    "from scipy.io.wavfile import write\n",
    "samplerate = 16000#int(clock) sample Ã  16khz\n",
    "file = \"sample_A_DEFORMED1_C0\"\n",
    "#convert the data into a 16 bit integer amplitude signal => change scale\n",
    "max_amplitude = np.max(np.abs(conduction['amplitude']))\n",
    "max_int16 = np.iinfo(np.int16).max\n",
    "#data = (conduction['amplitude'] * (max_int16/max_amplitude)).astype(np.int16)\n",
    "for index in range(len(samples)):\n",
    "    sample = (samples[index] * (max_int16/max_amplitude)).astype(np.int16)\n",
    "    write(file + str(index) + '.wav', samplerate, sample)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7f82ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the data and listening to it because why not!\n",
    "#it's cool to listen to something you're just seeing as numbers!\n",
    "sd.play(conduction, 1e5)\n",
    "status = sd.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f75d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d88704f0",
   "metadata": {},
   "source": [
    "### Idea 1 : using an SVM to separate the data\n",
    "Do PCA on the data \\\n",
    "Apply SVM on the data \\\n",
    "\n",
    "### Idea 2 : using a neural network to separate the data\n",
    "WPT (Wavelet package transform) \\\n",
    "Design a CNN (Convolutional Neural Network) \\\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15df5406",
   "metadata": {},
   "outputs": [],
   "source": [
    "16*1e3 / (3*1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79791d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "1/0.005333333333333333"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac77a28",
   "metadata": {},
   "source": [
    "#YAMNET PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92024a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the yamnet model\n",
    "model = hub.load('https://tfhub.dev/google/yamnet/1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba40665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_sample_rate(original_sample_rate, waveform,\n",
    "                       desired_sample_rate=16000):\n",
    "  \"\"\"Resample waveform if required.\"\"\"\n",
    "  if original_sample_rate != desired_sample_rate:\n",
    "    desired_length = int(round(float(len(waveform)) /\n",
    "                               original_sample_rate * desired_sample_rate))\n",
    "    waveform = scipy.signal.resample(waveform, desired_length)\n",
    "  return desired_sample_rate, waveform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310d96e8",
   "metadata": {},
   "source": [
    "### Loading the class types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfccbac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the name of the class with the top score when mean-aggregated across frames.\n",
    "def class_names_from_csv(class_map_csv_text):\n",
    "  \"\"\"Returns list of class names corresponding to score vector.\"\"\"\n",
    "  class_names = []\n",
    "  with tf.io.gfile.GFile(class_map_csv_text) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "      class_names.append(row['display_name'])\n",
    "\n",
    "  return class_names\n",
    "\n",
    "class_map_path = model.class_map_path().numpy()\n",
    "class_names = class_names_from_csv(class_map_path)\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0437573",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load a .wav file\n",
    "def load_wav_file(filename):\n",
    "    sample_rate, wav_data = wavfile.read(wav_file_name, 'rb')\n",
    "\n",
    "    #basic information from the extracted signal\n",
    "    duration = len(wav_data)/sample_rate\n",
    "    print(f'Sample rate: {sample_rate} Hz')\n",
    "    print(f'Total duration: {duration:.2f}s')\n",
    "    print(f'Size of the input: {len(wav_data)}')\n",
    "\n",
    "\n",
    "\n",
    "    #normalise the data\n",
    "    waveform = wav_data / tf.int16.max\n",
    "    return waveform\n",
    "\n",
    "    \n",
    "    \n",
    "wav_file_name = wav_folder_rx + wav_rx + '.wav'\n",
    "wavefile = load_wav_file(wav_file_name)\n",
    "\n",
    "_ = plt.plot(wavefile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfaeaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Audio of the laser\")\n",
    "print(Audio(wav_data, rate=sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07575f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, embeddings, spectrogram = model(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b874e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_np = scores.numpy()\n",
    "spectrogram_np = spectrogram.numpy()\n",
    "infered_class = class_names[scores_np.mean(axis=0).argmax()]\n",
    "print(f'The main sound is: {infered_class}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a389479e",
   "metadata": {},
   "source": [
    "### some data visualisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79099c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_sample_result(waveform):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot the waveform.\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.plot(waveform)\n",
    "    plt.xlim([0, len(waveform)])\n",
    "\n",
    "    # Plot the log-mel spectrogram (returned by the model).\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.imshow(spectrogram_np.T, aspect='auto', interpolation='nearest', origin='lower')\n",
    "\n",
    "    # Plot and label the model output scores for the top-scoring classes.\n",
    "    mean_scores = np.mean(scores, axis=0)\n",
    "    top_n = 10\n",
    "    top_class_indices = np.argsort(mean_scores)[::-1][:top_n]\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.imshow(scores_np[:, top_class_indices].T, aspect='auto', interpolation='nearest', cmap='gray_r')\n",
    "\n",
    "    # patch_padding = (PATCH_WINDOW_SECONDS / 2) / PATCH_HOP_SECONDS\n",
    "    # values from the model documentation\n",
    "    patch_padding = (0.025 / 2) / 0.01\n",
    "    plt.xlim([-patch_padding-0.5, scores.shape[0] + patch_padding-0.5])\n",
    "    # Label the top_N classes.\n",
    "    yticks = range(0, top_n, 1)\n",
    "    plt.yticks(yticks, [class_names[top_class_indices[x]] for x in yticks])\n",
    "    _ = plt.ylim(-0.5 + np.array([top_n, 0]))\n",
    "\n",
    "view_sample_result(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ec77dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classes = ['deformed', 'rx']\n",
    "map_class_to_id = {'deformed':0, 'rx':1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a41499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
